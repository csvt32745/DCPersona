#!/usr/bin/env python3
"""
è¤‡é›œåº¦è©•ä¼°ç³»çµ±æ¸¬è©¦è…³æœ¬

æ­¤è…³æœ¬æ¸¬è©¦æ–°çš„è¤‡é›œåº¦åˆ¤æ–·é‚è¼¯ï¼ŒåŒ…æ‹¬ï¼š
1. LLM é©…å‹•çš„è¤‡é›œåº¦è©•ä¼°
2. è¦å‰‡å‹è¤‡é›œåº¦è©•ä¼°
3. å…©è€…çš„çµåˆé‚è¼¯
4. Research Agent æµç¨‹æ•´åˆ
"""

import asyncio
import json
import logging
from typing import Dict, Any

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# å°å…¥ç›¸é—œæ¨¡çµ„
try:
    from agents.utils import (
        analyze_message_complexity,
        parse_complexity_assessment_result,
        combine_complexity_assessments,
        assess_message_complexity_with_llm
    )
    from agents.prompts import complexity_assessment_prompt
    from agents.configuration import AgentConfiguration
except ImportError as e:
    logger.error(f"å°å…¥å¤±æ•—: {e}")
    logger.error("è«‹ç¢ºä¿åœ¨æ­£ç¢ºçš„é …ç›®ç›®éŒ„ä¸­é‹è¡Œæ­¤è…³æœ¬")
    exit(1)


# æ¸¬è©¦ç”¨ä¾‹
TEST_MESSAGES = [
    {
        "content": "ä½ å¥½ï¼ä»Šå¤©å¤©æ°£æ€éº¼æ¨£ï¼Ÿ",
        "expected": "SIMPLE",
        "description": "ç°¡å–®å•å€™"
    },
    {
        "content": "è«‹æ¯”è¼ƒ Python å’Œ JavaScript åœ¨ 2024 å¹´çš„å°±æ¥­å‰æ™¯ï¼Œä¸¦åˆ†æå„è‡ªçš„å„ªç¼ºé»",
        "expected": "RESEARCH", 
        "description": "è¤‡é›œæ¯”è¼ƒåˆ†æ + æ™‚æ•ˆæ€§"
    },
    {
        "content": "!research æ©Ÿå™¨å­¸ç¿’çš„ç™¼å±•æ­·å²",
        "expected": "RESEARCH",
        "description": "å¼·åˆ¶ç ”ç©¶å‘½ä»¤"
    },
    {
        "content": "1 + 1 ç­‰æ–¼å¤šå°‘ï¼Ÿ",
        "expected": "SIMPLE",
        "description": "ç°¡å–®è¨ˆç®—"
    },
    {
        "content": "å°ç£æœ€æ–°çš„AIæ”¿ç­–æœ‰å“ªäº›ï¼Ÿå°ç§‘æŠ€æ¥­æœ‰ä»€éº¼å½±éŸ¿ï¼Ÿ",
        "expected": "RESEARCH",
        "description": "æ™‚æ•ˆæ€§è³‡è¨Šéœ€æ±‚"
    },
    {
        "content": "å¯«ä¸€é¦–é—œæ–¼æ˜Ÿæ˜Ÿçš„è©©",
        "expected": "SIMPLE", 
        "description": "å‰µæ„å…§å®¹"
    },
    {
        "content": "å¦‚ä½•å„ªåŒ–æ·±åº¦å­¸ç¿’æ¨¡å‹çš„è¨“ç·´é€Ÿåº¦ï¼Ÿæœ‰å“ªäº›æœ€æ–°çš„æŠ€è¡“æ–¹æ¡ˆï¼Ÿ",
        "expected": "RESEARCH",
        "description": "æŠ€è¡“å•é¡Œ + æœ€æ–°è³‡è¨Š"
    }
]


class MockLLMClient:
    """æ¨¡æ“¬ LLM å®¢æˆ¶ç«¯ç”¨æ–¼æ¸¬è©¦"""
    
    def __init__(self):
        # é è¨­çš„æ¨¡æ“¬å›æ‡‰
        self.mock_responses = {
            "ä½ å¥½ï¼ä»Šå¤©å¤©æ°£æ€éº¼æ¨£ï¼Ÿ": {
                "decision": "SIMPLE",
                "confidence": 0.9,
                "reasoning": "é€™æ˜¯ä¸€å€‹ç°¡å–®çš„å•å€™å’Œå¤©æ°£è©¢å•",
                "triggered_criteria": ["æ—¥å¸¸å°è©±"]
            },
            "è«‹æ¯”è¼ƒ Python å’Œ JavaScript åœ¨ 2024 å¹´çš„å°±æ¥­å‰æ™¯ï¼Œä¸¦åˆ†æå„è‡ªçš„å„ªç¼ºé»": {
                "decision": "RESEARCH", 
                "confidence": 0.95,
                "reasoning": "éœ€è¦æœ€æ–°å°±æ¥­å¸‚å ´æ•¸æ“šå’Œæ·±åº¦æ¯”è¼ƒåˆ†æ",
                "triggered_criteria": ["æ™‚æ•ˆæ€§éœ€æ±‚", "è¤‡é›œåˆ†æéœ€æ±‚", "æ¯”è¼ƒåˆ†æ"]
            },
            "!research æ©Ÿå™¨å­¸ç¿’çš„ç™¼å±•æ­·å²": {
                "decision": "RESEARCH",
                "confidence": 1.0,
                "reasoning": "ä½¿ç”¨è€…æ˜ç¢ºè¦æ±‚æ·±åº¦ç ”ç©¶",
                "triggered_criteria": ["å¼·åˆ¶ç ”ç©¶æŒ‡ä»¤"]
            }
        }
    
    async def ainvoke(self, prompt: str) -> 'MockResponse':
        """æ¨¡æ“¬ LLM èª¿ç”¨"""
        # å¾æç¤ºä¸­æå–è¨Šæ¯å…§å®¹
        message_start = prompt.find("ä½¿ç”¨è€…è¨Šæ¯ï¼š") + len("ä½¿ç”¨è€…è¨Šæ¯ï¼š")
        message_content = prompt[message_start:].strip()
        
        # æŸ¥æ‰¾é è¨­å›æ‡‰ï¼Œæˆ–ç”Ÿæˆç°¡å–®å›æ‡‰
        if message_content in self.mock_responses:
            response_data = self.mock_responses[message_content]
        else:
            # ç°¡å–®çš„å•Ÿç™¼å¼åˆ¤æ–·
            if any(word in message_content.lower() for word in ["ç ”ç©¶", "åˆ†æ", "æ¯”è¼ƒ", "æœ€æ–°", "!research"]):
                response_data = {
                    "decision": "RESEARCH",
                    "confidence": 0.7,
                    "reasoning": "æª¢æ¸¬åˆ°ç ”ç©¶ç›¸é—œé—œéµå­—",
                    "triggered_criteria": ["é—œéµå­—æª¢æ¸¬"]
                }
            else:
                response_data = {
                    "decision": "SIMPLE", 
                    "confidence": 0.8,
                    "reasoning": "çœ‹èµ·ä¾†æ˜¯ä¸€èˆ¬æ€§å•é¡Œ",
                    "triggered_criteria": []
                }
        
        # æ¨¡æ“¬ç¶²è·¯å»¶é²
        await asyncio.sleep(0.1)
        
        return MockResponse(json.dumps(response_data, ensure_ascii=False))


class MockResponse:
    """æ¨¡æ“¬ LLM å›æ‡‰ç‰©ä»¶"""
    
    def __init__(self, content: str):
        self.content = content


def test_rule_based_complexity():
    """æ¸¬è©¦è¦å‰‡å‹è¤‡é›œåº¦è©•ä¼°"""
    print("=" * 50)
    print("ğŸ” æ¸¬è©¦è¦å‰‡å‹è¤‡é›œåº¦è©•ä¼°")
    print("=" * 50)
    
    for i, test_case in enumerate(TEST_MESSAGES):
        content = test_case["content"]
        expected = test_case["expected"]
        description = test_case["description"]
        
        result = analyze_message_complexity(content)
        
        decision = "RESEARCH" if result["use_research"] else "SIMPLE"
        match = "âœ…" if decision == expected else "âŒ"
        
        print(f"\næ¸¬è©¦ {i+1}: {description}")
        print(f"è¨Šæ¯: {content}")
        print(f"é æœŸ: {expected} | å¯¦éš›: {decision} {match}")
        print(f"è¤‡é›œåº¦åˆ†æ•¸: {result['complexity_score']:.2f}")
        print(f"æª¢æ¸¬é—œéµå­—: {', '.join(result['detected_keywords'])}")


def test_llm_response_parsing():
    """æ¸¬è©¦ LLM å›æ‡‰è§£æ"""
    print("\n" + "=" * 50)
    print("ğŸ¤– æ¸¬è©¦ LLM å›æ‡‰è§£æ")
    print("=" * 50)
    
    # æ¸¬è©¦æ­£ç¢ºçš„ JSON æ ¼å¼
    valid_json = {
        "decision": "RESEARCH",
        "confidence": 0.85,
        "reasoning": "éœ€è¦æœ€æ–°è³‡è¨Šå’Œæ·±åº¦åˆ†æ",
        "triggered_criteria": ["æ™‚æ•ˆæ€§éœ€æ±‚", "è¤‡é›œåˆ†æéœ€æ±‚"]
    }
    
    result = parse_complexity_assessment_result(json.dumps(valid_json, ensure_ascii=False))
    print(f"\nâœ… æ­£ç¢º JSON è§£æ:")
    print(f"æ±ºç­–: {result['decision']}")
    print(f"ä¿¡å¿ƒ: {result['confidence']}")
    print(f"åŸå› : {result['reasoning']}")
    
    # æ¸¬è©¦ç°¡å–®æ ¼å¼
    simple_response = "RESEARCH"
    result = parse_complexity_assessment_result(simple_response)
    print(f"\nâœ… ç°¡å–®æ ¼å¼è§£æ:")
    print(f"æ±ºç­–: {result['decision']}")
    print(f"ä¿¡å¿ƒ: {result['confidence']}")
    
    # æ¸¬è©¦éŒ¯èª¤æ ¼å¼
    invalid_response = "é€™ä¸æ˜¯æœ‰æ•ˆçš„å›æ‡‰"
    result = parse_complexity_assessment_result(invalid_response)
    print(f"\nâš ï¸ éŒ¯èª¤æ ¼å¼è™•ç†:")
    print(f"æ±ºç­–: {result['decision']} (é™ç´š)")
    print(f"æ–¹æ³•: {result['method']}")


async def test_full_llm_assessment():
    """æ¸¬è©¦å®Œæ•´çš„ LLM è©•ä¼°æµç¨‹"""
    print("\n" + "=" * 50)
    print("ğŸ§  æ¸¬è©¦å®Œæ•´ LLM è©•ä¼°æµç¨‹")
    print("=" * 50)
    
    llm_client = MockLLMClient()
    
    for i, test_case in enumerate(TEST_MESSAGES[:3]):  # åªæ¸¬è©¦å‰ä¸‰å€‹ä»¥ç¯€çœæ™‚é–“
        content = test_case["content"]
        expected = test_case["expected"]
        description = test_case["description"]
        
        try:
            result = await assess_message_complexity_with_llm(content, llm_client)
            
            decision = result["final_decision"]
            match = "âœ…" if decision == expected else "âŒ"
            
            print(f"\næ¸¬è©¦ {i+1}: {description}")
            print(f"è¨Šæ¯: {content}")
            print(f"é æœŸ: {expected} | å¯¦éš›: {decision} {match}")
            print(f"æ–¹æ³•: {result['method']}")
            print(f"ä¿¡å¿ƒ: {result['confidence']:.2f}")
            print(f"åŸå› : {result['reasoning'][:100]}...")
            
        except Exception as e:
            print(f"\nâŒ æ¸¬è©¦ {i+1} å¤±æ•—: {e}")


def test_complexity_assessment_prompt():
    """æ¸¬è©¦è¤‡é›œåº¦è©•ä¼°æç¤ºæ ¼å¼"""
    print("\n" + "=" * 50)
    print("ğŸ“ æ¸¬è©¦è¤‡é›œåº¦è©•ä¼°æç¤º")
    print("=" * 50)
    
    test_message = "è«‹åˆ†æ 2024 å¹´äººå·¥æ™ºæ…§çš„ç™¼å±•è¶¨å‹¢"
    formatted_prompt = complexity_assessment_prompt.format(message=test_message)
    
    print("âœ… æç¤ºæ ¼å¼æ­£ç¢ºç”Ÿæˆ")
    print(f"é•·åº¦: {len(formatted_prompt)} å­—ç¬¦")
    print(f"åŒ…å«è©•ä¼°ç¶­åº¦: {'âœ…' if 'è©•ä¼°ç¶­åº¦' in formatted_prompt else 'âŒ'}")
    print(f"åŒ…å«è¼¸å‡ºæ ¼å¼: {'âœ…' if 'JSON' in formatted_prompt else 'âŒ'}")
    print(f"åŒ…å«æ¸¬è©¦è¨Šæ¯: {'âœ…' if test_message in formatted_prompt else 'âŒ'}")


async def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("ğŸŒŸ ä¸‰è§’åˆè¯è¤‡é›œåº¦è©•ä¼°ç³»çµ±æ¸¬è©¦")
    print("æ¸¬è©¦æ–°çš„ LLM + è¦å‰‡æ··åˆåˆ¤æ–·é‚è¼¯")
    
    try:
        # 1. æ¸¬è©¦è¦å‰‡å‹è©•ä¼°
        test_rule_based_complexity()
        
        # 2. æ¸¬è©¦ LLM å›æ‡‰è§£æ
        test_llm_response_parsing()
        
        # 3. æ¸¬è©¦æç¤ºæ ¼å¼
        test_complexity_assessment_prompt()
        
        # 4. æ¸¬è©¦å®Œæ•´ LLM æµç¨‹
        await test_full_llm_assessment()
        
        print("\n" + "=" * 50)
        print("âœ¨ æ‰€æœ‰æ¸¬è©¦å®Œæˆï¼")
        print("æ–°çš„è¤‡é›œåº¦åˆ¤æ–·ç³»çµ±å·²æº–å‚™å°±ç·’")
        print("=" * 50)
        
    except Exception as e:
        logger.error(f"æ¸¬è©¦éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)


if __name__ == "__main__":
    asyncio.run(main())