"""
æ¸¬è©¦ agent_core/graph.py çµ±ä¸€ LangGraph å¯¦ä½œ
"""

import pytest
from unittest.mock import patch, MagicMock
import sys
import os

# èª¿æ•´å°å…¥è·¯å¾‘ï¼Œç¢ºä¿å¯ä»¥æ‰¾åˆ° AgentCLI æ¨¡çµ„
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from agent_core.graph import UnifiedAgent, create_unified_agent, create_agent_graph
from schemas.agent_types import OverallState, MsgNode


def get_test_config(agent_config=None):
    """å–å¾—æ¸¬è©¦ç”¨çš„æ¨™æº–é…ç½®"""
    base_config = {
        "gemini_api_key": "test_key",
        "llm_models": {
            "tool_analysis": {"model": "gemini-2.0-flash-exp", "temperature": 0.1},
            "final_answer": {"model": "gemini-2.0-flash-exp", "temperature": 0.7}
        },
        "agent": {
            "tools": {},
            "behavior": {"max_tool_rounds": 1}
        }
    }
    
    if agent_config:
        base_config["agent"].update(agent_config)
    
    return base_config


class TestUnifiedAgent:
    """æ¸¬è©¦ UnifiedAgent é¡åˆ¥"""
    
    def test_agent_creation(self):
        """æ¸¬è©¦ Agent å‰µå»º"""
        config = get_test_config({
            "tools": {"google_search": {"enabled": False}},
            "behavior": {"max_tool_rounds": 1}
        })
        
        with patch('agent_core.graph.ChatGoogleGenerativeAI'):
            agent = UnifiedAgent(config)
            
            assert agent.config == config
            assert agent.agent_config == config["agent"]
            assert agent.tools_config == config["agent"]["tools"]
            assert agent.behavior_config == config["agent"]["behavior"]
    
    def test_agent_creation_with_default_config(self):
        """æ¸¬è©¦ä½¿ç”¨é è¨­é…ç½®å‰µå»º Agent"""
        with patch('agent_core.graph.load_config') as mock_load_config, \
             patch('agent_core.graph.ChatGoogleGenerativeAI'):
            mock_load_config.return_value = {
                "gemini_api_key": "test_key",
                "llm_models": {
                    "tool_analysis": {"model": "gemini-2.0-flash-exp", "temperature": 0.1},
                    "final_answer": {"model": "gemini-2.0-flash-exp", "temperature": 0.7}
                },
                "agent": {"tools": {}, "behavior": {}}
            }
            
            agent = UnifiedAgent()
            
            mock_load_config.assert_called_once()
    
    def test_build_graph_pure_conversation_mode(self):
        """æ¸¬è©¦ç´”å°è©±æ¨¡å¼çš„åœ–å»ºç«‹"""
        config = get_test_config({
            "tools": {},
            "behavior": {"max_tool_rounds": 0}
        })
        
        with patch('agent_core.graph.ChatGoogleGenerativeAI'):
            agent = UnifiedAgent(config)
            graph = agent.build_graph()
            
            assert graph is not None
            # åœ–æ‡‰è©²åŒ…å«æ‰€æœ‰ç¯€é»ï¼Œä½†æµç¨‹æœƒè·³éå·¥å…·ç›¸é—œç¯€é»
    
    def test_build_graph_tool_mode(self):
        """æ¸¬è©¦å·¥å…·æ¨¡å¼çš„åœ–å»ºç«‹"""
        config = get_test_config({
            "tools": {"google_search": {"enabled": True}},
            "behavior": {"max_tool_rounds": 2}
        })
        
        with patch('agent_core.graph.ChatGoogleGenerativeAI'):
            agent = UnifiedAgent(config)
            graph = agent.build_graph()
            
            assert graph is not None
    
    @pytest.mark.asyncio
    async def test_generate_query_or_plan_no_messages(self):
        """æ¸¬è©¦ç„¡è¨Šæ¯çš„æŸ¥è©¢ç”Ÿæˆ"""
        config = get_test_config()
        
        with patch('agent_core.graph.ChatGoogleGenerativeAI'):
            agent = UnifiedAgent(config)
            
            state = OverallState()
            result = await agent.generate_query_or_plan(state)
            
            assert result["finished"] is True
    
    @pytest.mark.asyncio
    async def test_generate_query_or_plan_with_user_message(self):
        """æ¸¬è©¦æœ‰ç”¨æˆ¶è¨Šæ¯çš„æŸ¥è©¢ç”Ÿæˆ"""
        config = get_test_config({
            "tools": {"google_search": {"enabled": True}},
            "behavior": {"max_tool_rounds": 1}
        })
        
        with patch('agent_core.graph.ChatGoogleGenerativeAI'):
            agent = UnifiedAgent(config)
            
            state = OverallState(
                messages=[MsgNode(role="user", content="æœå°‹æœ€æ–°çš„ AI æ–°è")]
            )
            
            result = await agent.generate_query_or_plan(state)
            
            assert "tool_round" in result
            assert "needs_tools" in result
            assert "search_queries" in result
            assert "research_topic" in result
    
    def test_analyze_tool_necessity(self):
        """æ¸¬è©¦å·¥å…·éœ€æ±‚åˆ†æ"""
        config = get_test_config()
        
        with patch('agent_core.graph.ChatGoogleGenerativeAI'):
            agent = UnifiedAgent(config)
            
            # ç›´æ¥æ¸¬è©¦ fallback æ–¹æ³•ä»¥ç¢ºä¿é—œéµå­—æª¢æ¸¬é‚è¼¯æ­£ç¢º
            # åŒ…å«å·¥å…·é—œéµå­—çš„å…§å®¹
            assert agent._analyze_tool_necessity_fallback([MsgNode(role="user", content="è«‹æœå°‹æœ€æ–°è³‡è¨Š")]) is True
            assert agent._analyze_tool_necessity_fallback([MsgNode(role="user", content="æŸ¥è©¢ä»Šå¤©çš„æ–°è")]) is True
            
            # ä¸åŒ…å«å·¥å…·é—œéµå­—çš„å…§å®¹  
            assert agent._analyze_tool_necessity_fallback([MsgNode(role="user", content="ä½ å¥½å—ï¼Ÿ")]) is False
            assert agent._analyze_tool_necessity_fallback([MsgNode(role="user", content="è¬è¬ä½ çš„å¹«åŠ©")]) is False
    
    def test_tool_selection_no_tools_needed(self):
        """æ¸¬è©¦ä¸éœ€è¦å·¥å…·æ™‚çš„å·¥å…·é¸æ“‡"""
        config = get_test_config()
        
        with patch('agent_core.graph.ChatGoogleGenerativeAI'):
            agent = UnifiedAgent(config)
            
            state = OverallState(needs_tools=False)
            result = agent.tool_selection(state)
            
            assert result["selected_tool"] is None
            assert result["available_tools"] == []
    
    def test_tool_selection_with_available_tools(self):
        """æ¸¬è©¦æœ‰å¯ç”¨å·¥å…·æ™‚çš„å·¥å…·é¸æ“‡"""
        config = get_test_config({
            "tools": {
                "google_search": {"enabled": True, "priority": 1},
                "citation": {"enabled": True, "priority": 2}
            }
        })
        
        with patch('agent_core.graph.ChatGoogleGenerativeAI'):
            agent = UnifiedAgent(config)
            
            # æ¨¡æ“¬ self.google_client ä»¥ç¢ºä¿ google_search è¢«è¦–ç‚ºå¯ç”¨
            with patch.object(agent, 'google_client', new=MagicMock()):
                state = OverallState(needs_tools=True)
                result = agent.tool_selection(state)
                
                assert "google_search" in result["available_tools"]
                assert "citation" in result["available_tools"]
                assert result["selected_tool"] == "google_search"  # å„ªå…ˆç´šè¼ƒé«˜
    
    @pytest.mark.asyncio
    async def test_execute_tool_no_tool_selected(self):
        """æ¸¬è©¦æ²’æœ‰é¸æ“‡å·¥å…·æ™‚çš„åŸ·è¡Œ"""
        config = get_test_config()
        
        with patch('agent_core.graph.ChatGoogleGenerativeAI'):
            agent = UnifiedAgent(config)
            
            state = OverallState(selected_tool=None)
            result = await agent.execute_tool(state)
            
            assert result["tool_results"] == []
    
    @pytest.mark.asyncio
    async def test_execute_google_search_tool(self):
        """æ¸¬è©¦åŸ·è¡Œ Google æœå°‹å·¥å…·"""
        config = get_test_config({
            "tools": {"google_search": {"enabled": True}}
        })
        
        with patch('agent_core.graph.ChatGoogleGenerativeAI'), \
             patch('agent_core.graph.Client') as mock_google_client_class:
            
            # æ¨¡æ“¬ Google Client çš„è¡Œç‚º
            mock_google_client_instance = MagicMock()
            mock_response = MagicMock()
            
            # æ¨¡æ“¬ generate_content çš„å›æ‡‰
            mock_content_response = MagicMock()
            mock_content_response.text = "é€™æ˜¯æ¨¡æ“¬çš„ Google æœå°‹çµæœã€‚"
            
            mock_candidate = MagicMock()
            mock_candidate.grounding_metadata = MagicMock()
            mock_candidate.grounding_metadata.grounding_chunks = []
            mock_response.candidates = [mock_candidate]
            
            mock_google_client_instance.models.generate_content.return_value = mock_content_response
            mock_google_client_class.return_value = mock_google_client_instance
            
            agent = UnifiedAgent(config)
            
            state = OverallState(
                selected_tool="google_search",
                search_queries=["æ¸¬è©¦æŸ¥è©¢"]
            )
            
            result = await agent.execute_tool(state)
            
            assert len(result["tool_results"]) > 0
            assert result["tool_round"] == 1
            assert "é€™æ˜¯æ¨¡æ“¬çš„ Google æœå°‹çµæœã€‚" in result["tool_results"][0]
    
    @pytest.mark.asyncio
    async def test_execute_citation_tool(self):
        """æ¸¬è©¦åŸ·è¡Œå¼•ç”¨å·¥å…·"""
        config = get_test_config()
        
        with patch('agent_core.graph.ChatGoogleGenerativeAI'):
            agent = UnifiedAgent(config)
            
            state = OverallState(
                selected_tool="citation",
                tool_results=["æ¸¬è©¦çµæœ1", "æ¸¬è©¦çµæœ2"]
            )
            
            result = await agent.execute_tool(state)
            
            assert len(result["tool_results"]) > 0
            assert "[1]" in result["tool_results"][0]
    
    @pytest.mark.asyncio
    async def test_reflection_enabled(self):
        """æ¸¬è©¦å•Ÿç”¨åæ€çš„æƒ…æ³"""
        config = get_test_config({
            "behavior": {"enable_reflection": True}
        })
        
        with patch('agent_core.graph.ChatGoogleGenerativeAI'):
            agent = UnifiedAgent(config)
            
            state = OverallState(
                tool_results=["è¶³å¤ é•·çš„æ¸¬è©¦çµæœå…§å®¹ä¾†é€šéå……åˆ†æ€§æª¢æŸ¥"],
                research_topic="æ¸¬è©¦ä¸»é¡Œ"
            )
            
            result = await agent.reflection(state)
        
        assert "is_sufficient" in result
        assert "reflection_complete" in result
        assert result["reflection_complete"] is True
    
    @pytest.mark.asyncio
    async def test_reflection_disabled(self):
        """æ¸¬è©¦ç¦ç”¨åæ€çš„æƒ…æ³"""
        config = get_test_config({
            "behavior": {"enable_reflection": False}
        })
        
        with patch('agent_core.graph.ChatGoogleGenerativeAI'):
            agent = UnifiedAgent(config)
            
            state = OverallState()
            result = await agent.reflection(state)
            
            assert result["is_sufficient"] is True
    
    def test_evaluate_research_sufficient(self):
        """æ¸¬è©¦çµæœå……åˆ†æ™‚çš„ç ”ç©¶è©•ä¼°"""
        config = get_test_config()
        
        with patch('agent_core.graph.ChatGoogleGenerativeAI'):
            agent = UnifiedAgent(config)
            
            state = OverallState(
                is_sufficient=True,
                tool_round=1
            )
            
            result = agent.evaluate_research(state)
            assert result == "finish"
    
    def test_evaluate_research_max_rounds_reached(self):
        """æ¸¬è©¦é”åˆ°æœ€å¤§è¼ªæ¬¡æ™‚çš„ç ”ç©¶è©•ä¼°"""
        config = get_test_config({
            "behavior": {"max_tool_rounds": 2}
        })
        
        with patch('agent_core.graph.ChatGoogleGenerativeAI'):
            agent = UnifiedAgent(config)
            
            state = OverallState(
                is_sufficient=False,
                tool_round=2
            )
            
            result = agent.evaluate_research(state)
            assert result == "finish"
    
    def test_evaluate_research_continue(self):
        """æ¸¬è©¦ç¹¼çºŒç ”ç©¶çš„æƒ…æ³"""
        config = get_test_config({
            "behavior": {"max_tool_rounds": 3}
        })
        
        with patch('agent_core.graph.ChatGoogleGenerativeAI'):
            agent = UnifiedAgent(config)
            
            state = OverallState(
                is_sufficient=False,
                tool_round=1
            )
            
            result = agent.evaluate_research(state)
            assert result == "continue"
    
    @pytest.mark.asyncio
    async def test_finalize_answer_no_messages(self):
        """æ¸¬è©¦ç„¡è¨Šæ¯æ™‚çš„æœ€çµ‚ç­”æ¡ˆç”Ÿæˆ"""
        config = get_test_config()
        
        with patch('agent_core.graph.ChatGoogleGenerativeAI'):
            agent = UnifiedAgent(config)
            
            state = OverallState()
            result = await agent.finalize_answer(state)
            
            assert result["finished"] is True
    
    @pytest.mark.asyncio
    async def test_finalize_answer_with_context(self):
        """æ¸¬è©¦æœ‰ä¸Šä¸‹æ–‡çš„æœ€çµ‚ç­”æ¡ˆç”Ÿæˆ"""
        config = get_test_config()
        
        with patch('agent_core.graph.ChatGoogleGenerativeAI') as mock_llm_class:
            # è¨­ç½®æ¨¡æ“¬çš„ LLM å›æ‡‰
            mock_llm_instance = MagicMock()
            mock_response = MagicMock()
            mock_response.content = "é—œæ–¼ä½ å•çš„ã€Œä»€éº¼æ˜¯ AIï¼Ÿã€ï¼Œæˆ‘æ‰¾åˆ°äº†ä¸€äº›æœ‰ç”¨çš„è³‡è¨Šå‘¢ï¼âœ¨\n\nAI æ˜¯äººå·¥æ™ºæ…§çš„ç¸®å¯«ï¼ŒAI æŠ€è¡“æ­£åœ¨å¿«é€Ÿç™¼å±•\n\nå¸Œæœ›é€™äº›å°ä½ æœ‰å¹«åŠ©ï¼é‚„æœ‰ä»€éº¼æƒ³äº†è§£çš„å—ï¼ŸğŸ˜Š"
            mock_llm_instance.invoke.return_value = mock_response
            mock_llm_class.return_value = mock_llm_instance
            
            agent = UnifiedAgent(config)
            
            state = OverallState(
                messages=[MsgNode(role="user", content="ä»€éº¼æ˜¯ AIï¼Ÿ")],
                tool_results=["AI æ˜¯äººå·¥æ™ºæ…§çš„ç¸®å¯«", "AI æŠ€è¡“æ­£åœ¨å¿«é€Ÿç™¼å±•"]
            )
            
            result = await agent.finalize_answer(state)
            
            assert "final_answer" in result
            assert "AI" in result["final_answer"]
            assert result["finished"] is True
    
    @pytest.mark.asyncio
    async def test_finalize_answer_without_context(self):
        """æ¸¬è©¦ç„¡ä¸Šä¸‹æ–‡çš„æœ€çµ‚ç­”æ¡ˆç”Ÿæˆ"""
        config = get_test_config()
        
        with patch('agent_core.graph.ChatGoogleGenerativeAI') as mock_llm_class:
            # è¨­ç½®æ¨¡æ“¬çš„ LLM å›æ‡‰
            mock_llm_instance = MagicMock()
            mock_response = MagicMock()
            mock_response.content = "å—¨ï¼é—œæ–¼ã€Œä½ å¥½ã€ï¼Œæˆ‘å¾ˆæ¨‚æ„å’Œä½ èŠèŠï½é›–ç„¶æˆ‘ç¾åœ¨æ²’æœ‰é¡å¤–çš„æœå°‹è³‡è¨Šï¼Œä½†æˆ‘æœƒç›¡æˆ‘æ‰€çŸ¥ä¾†å›ç­”ä½ ï¼ğŸ˜Š æœ‰ä»€éº¼ç‰¹åˆ¥æƒ³èŠçš„å—ï¼Ÿ"
            mock_llm_instance.invoke.return_value = mock_response
            mock_llm_class.return_value = mock_llm_instance
            
            agent = UnifiedAgent(config)
            
            state = OverallState(
                messages=[MsgNode(role="user", content="ä½ å¥½")],
                tool_results=[]
            )
            
            result = await agent.finalize_answer(state)
            
            assert "final_answer" in result
            assert "ä½ å¥½" in result["final_answer"]
            assert result["finished"] is True
    
    @pytest.mark.asyncio
    async def test_evaluate_results_sufficiency(self):
        """æ¸¬è©¦çµæœå……åˆ†æ€§è©•ä¼°"""
        config = get_test_config({
            "behavior": {"enable_reflection": True}
        })
        
        with patch('agent_core.graph.ChatGoogleGenerativeAI'):
            agent = UnifiedAgent(config)

            # å‡è¨­ LLM åˆ¤æ–·ç‚ºå……åˆ†
            with patch.object(agent, '_evaluate_results_sufficiency', return_value=True) as mock_sufficiency:
                state = OverallState(tool_results=["ä¸€äº›å·¥å…·çµæœ"], research_topic="æ¸¬è©¦ä¸»é¡Œ")
                
                result = await agent.reflection(state)

                mock_sufficiency.assert_called_once_with(["ä¸€äº›å·¥å…·çµæœ"], "æ¸¬è©¦ä¸»é¡Œ")
                assert result["is_sufficient"] is True
                assert result["reflection_complete"] is True


def test_create_unified_agent():
    """æ¸¬è©¦ä¾¿åˆ©å‡½æ•¸ create_unified_agent"""
    with patch('agent_core.graph.load_config') as mock_load_config, \
         patch('agent_core.graph.ChatGoogleGenerativeAI'):
        mock_load_config.return_value = get_test_config()
        
        agent = create_unified_agent()
        
        assert isinstance(agent, UnifiedAgent)


def test_create_agent_graph():
    """æ¸¬è©¦ä¾¿åˆ©å‡½æ•¸ create_agent_graph"""
    config = get_test_config({
        "behavior": {"max_tool_rounds": 0}
    })
    
    with patch('agent_core.graph.ChatGoogleGenerativeAI'):
        graph = create_agent_graph(config)
        
        assert graph is not None


if __name__ == "__main__":
    pytest.main([__file__, "-v"]) 