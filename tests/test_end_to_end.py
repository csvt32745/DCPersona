"""
ç«¯åˆ°ç«¯æ¸¬è©¦å¥—ä»¶

æ¸¬è©¦å®Œæ•´çš„ Discord Bot æµç¨‹å’Œæ‰€æœ‰åŠŸèƒ½çµ„åˆï¼ŒåŒ…æ‹¬å¤šæ¨¡æ…‹è¼¸å…¥æ”¯æ´ã€‚
"""

import pytest
import asyncio
from unittest.mock import Mock, AsyncMock, patch, MagicMock
from typing import Dict, Any, List
import os
from base64 import b64encode

import discord

from schemas.agent_types import MsgNode, OverallState
from schemas.config_types import AppConfig, AgentConfig, AgentBehaviorConfig, LLMConfig, DiscordConfig, ToolConfig, LLMProviderConfig, StreamingConfig, PromptSystemConfig, PromptPersonaConfig
from discord_bot.message_handler import DiscordMessageHandler
from discord_bot.message_collector import collect_message, CollectedMessages, ProcessedMessage
from agent_core.graph import UnifiedAgent, create_unified_agent
from utils.config_loader import load_typed_config
from cli_main import main as cli_main


def get_comprehensive_test_config():
    """å‰µå»ºå®Œæ•´çš„æ¸¬è©¦é…ç½®"""
    mock_google_provider_config = LLMProviderConfig(api_key="test_key_12345")
    
    mock_llm_config = LLMConfig(
        providers={"google": mock_google_provider_config}
    )
    
    return AppConfig(
        agent=AgentConfig(
            tools={
                "google_search": ToolConfig(enabled=True, priority=1)
            },
            behavior=AgentBehaviorConfig(
                max_tool_rounds=2, 
                enable_reflection=True
            )
        ),
        discord=DiscordConfig(
            bot_token="test_token",
            enable_conversation_history=True,
            status_message="æ¸¬è©¦ AI åŠ©æ‰‹",
            client_id="123456789"
        ),
        llm=mock_llm_config,
        streaming=StreamingConfig(
            enabled=True,
            min_content_length=100
        ),
        prompt_system=PromptSystemConfig(
            persona=PromptPersonaConfig(
                random_selection=False,
                default_persona="helpful_assistant",
                persona_directory="persona"
            )
        )
    )


class TestEndToEndFlow:
    """ç«¯åˆ°ç«¯æµç¨‹æ¸¬è©¦é¡"""
    
    @pytest.mark.asyncio
    async def test_discord_bot_complete_flow(self):
        """æ¸¬è©¦ Discord Bot å®Œæ•´æµç¨‹"""
        # æ¨¡æ“¬ Discord è¨Šæ¯
        mock_message = Mock(spec=discord.Message)
        mock_message.content = "è«‹å¹«æˆ‘æœå°‹æœ€æ–°çš„ AI ç™¼å±•"
        mock_message.author = Mock()
        mock_message.author.bot = False
        mock_message.author.id = 12345
        mock_message.author.display_name = "TestUser"
        mock_message.channel = Mock()
        mock_message.channel.id = 67890
        mock_message.guild = Mock()
        mock_message.guild.name = "TestGuild"
        mock_message.channel.name = "general"
        mock_message.attachments = []
        mock_message.embeds = []
        mock_message.reply = AsyncMock()
        mock_message.reference = None
        
        # æ¨¡æ“¬é »é“æ­·å²
        async def mock_history():
            return
            yield
        mock_message.channel.history = Mock(return_value=mock_history())
        
        test_config = get_comprehensive_test_config()
        
        with patch('discord_bot.message_handler.load_typed_config', return_value=test_config), \
             patch('discord_bot.message_handler.collect_message') as mock_collect, \
             patch('agent_core.graph.UnifiedAgent') as mock_unified_agent, \
             patch('discord_bot.message_handler.DiscordProgressAdapter') as mock_adapter:
            
            # è¨­ç½®è¨Šæ¯æ”¶é›†æ¨¡æ“¬
            test_message = MsgNode(
                role="user",
                content="è«‹å¹«æˆ‘æœå°‹æœ€æ–°çš„ AI ç™¼å±•",
                metadata={"user_id": 12345}
            )
            
            mock_collect.return_value = CollectedMessages(
                messages=[test_message],
                user_warnings=set()
            )
            
            # è¨­ç½® Agent æ¨¡æ“¬
            mock_agent = Mock()
            mock_agent.add_progress_observer = Mock()
            mock_agent.build_graph = Mock()
            
            mock_graph = Mock()
            mock_graph.ainvoke = AsyncMock(return_value={
                "final_answer": "æœ€æ–°çš„ AI ç™¼å±•åŒ…æ‹¬å¤§å‹èªè¨€æ¨¡å‹ã€å¤šæ¨¡æ…‹ AI å’Œè‡ªå‹•åŒ–å·¥å…·...",
                "sources": [
                    {"title": "AI 2024 è¶¨å‹¢", "url": "https://example.com/ai-trends"}
                ],
                "finished": True
            })
            mock_agent.build_graph.return_value = mock_graph
            mock_unified_agent.return_value = mock_agent
            
            # è¨­ç½®é€²åº¦é©é…å™¨æ¨¡æ“¬
            mock_adapter_instance = Mock()
            mock_adapter_instance.on_progress_update = AsyncMock()  # ğŸ”¥ æ–°å¢ï¼šæ”¯æ´ on_progress_update
            mock_adapter_instance.on_completion = AsyncMock()
            mock_adapter_instance.cleanup = AsyncMock()
            mock_adapter_instance.on_error = AsyncMock()
            mock_adapter_instance._streaming_message = None
            mock_adapter.return_value = mock_adapter_instance
            
            # åŸ·è¡Œæ¸¬è©¦
            handler = DiscordMessageHandler()
            
            # æ¨¡æ“¬ discord_client ä¸¦è¨­ç½® unified_agent
            mock_discord_client = Mock()
            mock_discord_client.unified_agent = mock_agent
            mock_discord_client.emoji_handler = Mock()
            handler.set_discord_client(mock_discord_client)
            
            success = await handler.handle_message(mock_message)
            
            # é©—è­‰çµæœ
            assert success is True
            mock_collect.assert_called_once()
            mock_agent.add_progress_observer.assert_called_once()
            mock_graph.ainvoke.assert_called_once()
            mock_adapter_instance.on_completion.assert_called_once()
    
    @pytest.mark.asyncio
    async def test_discord_bot_multimodal_flow(self):
        """æ¸¬è©¦ Discord Bot å¤šæ¨¡æ…‹è¼¸å…¥æµç¨‹"""
        # æ¨¡æ“¬åŒ…å«åœ–ç‰‡çš„ Discord è¨Šæ¯
        mock_message = Mock(spec=discord.Message)
        mock_message.content = "è«‹åˆ†æé€™å¼µåœ–ç‰‡çš„å…§å®¹"
        mock_message.author = Mock()
        mock_message.author.bot = False
        mock_message.author.id = 12345
        mock_message.author.display_name = "TestUser"
        mock_message.channel = Mock()
        mock_message.channel.id = 67890
        mock_message.guild = Mock()
        mock_message.guild.name = "TestGuild"
        mock_message.channel.name = "general"
        mock_message.embeds = []
        mock_message.reply = AsyncMock()
        mock_message.reference = None
        
        # æ¨¡æ“¬åœ–ç‰‡é™„ä»¶
        mock_attachment = Mock()
        mock_attachment.content_type = "image/jpeg"
        mock_attachment.filename = "test.jpg"
        mock_attachment.url = "https://example.com/test.jpg"
        mock_message.attachments = [mock_attachment]
        
        # æ¨¡æ“¬é »é“æ­·å²
        async def mock_history():
            return
            yield
        mock_message.channel.history = Mock(return_value=mock_history())
        
        test_config = get_comprehensive_test_config()
        
        with patch('discord_bot.message_handler.load_typed_config', return_value=test_config), \
             patch('discord_bot.message_handler.collect_message') as mock_collect, \
             patch('agent_core.graph.UnifiedAgent') as mock_unified_agent, \
             patch('discord_bot.message_handler.DiscordProgressAdapter') as mock_adapter:
            
            # è¨­ç½®å¤šæ¨¡æ…‹è¨Šæ¯æ”¶é›†æ¨¡æ“¬
            multimodal_content = [
                {"type": "text", "text": "<@12345> TestUser: è«‹åˆ†æé€™å¼µåœ–ç‰‡çš„å…§å®¹"},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": "data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD..."
                    }
                }
            ]
            
            test_message = MsgNode(
                role="user",
                content=multimodal_content,
                metadata={"user_id": 12345}
            )
            
            mock_collect.return_value = CollectedMessages(
                messages=[test_message],
                user_warnings=set()
            )
            
            # è¨­ç½® Agent æ¨¡æ“¬
            mock_agent = Mock()
            mock_agent.add_progress_observer = Mock()
            mock_agent.build_graph = Mock()
            
            mock_graph = Mock()
            mock_graph.ainvoke = AsyncMock(return_value={
                "final_answer": "é€™å¼µåœ–ç‰‡é¡¯ç¤ºäº†ä¸€å€‹ç¾éº—çš„é¢¨æ™¯ï¼ŒåŒ…å«å±±è„ˆå’Œæ¹–æ³Š...",
                "sources": [],
                "finished": True
            })
            mock_agent.build_graph.return_value = mock_graph
            mock_unified_agent.return_value = mock_agent
            
            # è¨­ç½®é€²åº¦é©é…å™¨æ¨¡æ“¬
            mock_adapter_instance = Mock()
            mock_adapter_instance.on_progress_update = AsyncMock()  # ğŸ”¥ æ–°å¢ï¼šæ”¯æ´ on_progress_update
            mock_adapter_instance.on_completion = AsyncMock()
            mock_adapter_instance.cleanup = AsyncMock()
            mock_adapter_instance.on_error = AsyncMock()
            mock_adapter_instance._streaming_message = None
            mock_adapter.return_value = mock_adapter_instance
            
            # åŸ·è¡Œæ¸¬è©¦
            handler = DiscordMessageHandler()
            
            # æ¨¡æ“¬ discord_client ä¸¦è¨­ç½® unified_agent
            mock_discord_client = Mock()
            mock_discord_client.unified_agent = mock_agent
            mock_discord_client.emoji_handler = Mock()
            handler.set_discord_client(mock_discord_client)
            
            success = await handler.handle_message(mock_message)
            
            # é©—è­‰çµæœ
            assert success is True
            mock_collect.assert_called_once()
            
            # é©—è­‰å‚³éçµ¦ Agent çš„è¨Šæ¯åŒ…å«å¤šæ¨¡æ…‹å…§å®¹
            call_args = mock_graph.ainvoke.call_args
            state = call_args[0][0]  # ç¬¬ä¸€å€‹ä½ç½®åƒæ•¸æ˜¯ state
            assert len(state.messages) == 1
            assert isinstance(state.messages[0].content, list)
            assert len(state.messages[0].content) == 2
            assert state.messages[0].content[0]["type"] == "text"
            assert state.messages[0].content[1]["type"] == "image_url"
    
    @pytest.mark.asyncio
    async def test_agent_with_tools(self):
        """æ¸¬è©¦ Agent å·¥å…·ä½¿ç”¨æµç¨‹"""
        config = get_comprehensive_test_config()
        
        with patch.dict('os.environ', {'GEMINI_API_KEY': 'test_key_12345'}):
            agent = UnifiedAgent(config)
            
            # æº–å‚™æ¸¬è©¦ç‹€æ…‹
            initial_state = OverallState(
                messages=[
                    MsgNode(role="user", content="è«‹æœå°‹ Python æœ€æ–°ç‰ˆæœ¬è³‡è¨Š")
                ],
                tool_round=0,
                finished=False
            )
            
            # ç”±æ–¼ tool_analysis_llm æœªåˆå§‹åŒ–ï¼Œæœƒä½¿ç”¨å›é€€é‚è¼¯
            # åŸ·è¡Œè¨ˆåŠƒç”Ÿæˆ
            result = await agent.generate_query_or_plan(initial_state)
            
            # é©—è­‰è¨ˆåŠƒç”Ÿæˆçµæœï¼ˆä½¿ç”¨å›é€€é‚è¼¯ï¼‰
            assert "agent_plan" in result
            assert result["agent_plan"].reasoning == "LLM æœªå¯ç”¨ï¼Œä½¿ç”¨ç°¡åŒ–é‚è¼¯æ±ºç­–"
            # ç”±æ–¼æ²’æœ‰çœŸæ­£çš„ LLMï¼Œneeds_tools å¯èƒ½ç‚º Falseï¼Œé€™æ˜¯é æœŸçš„
    
    @pytest.mark.asyncio
    async def test_streaming_functionality(self):
        """æ¸¬è©¦ä¸²æµåŠŸèƒ½"""
        config = get_comprehensive_test_config()
        config.streaming.enabled = True
        
        with patch.dict('os.environ', {'GEMINI_API_KEY': 'test_key_12345'}):
            agent = UnifiedAgent(config)
            
            # æº–å‚™æ¸¬è©¦ç‹€æ…‹
            test_state = OverallState(
                messages=[
                    MsgNode(role="user", content="è«‹è§£é‡‹ä»€éº¼æ˜¯æ©Ÿå™¨å­¸ç¿’")
                ],
                finished=False,
                tool_results=["æ©Ÿå™¨å­¸ç¿’æ˜¯äººå·¥æ™ºæ…§çš„ä¸€å€‹åˆ†æ”¯..."]
            )
            
            # æ¨¡æ“¬ä¸²æµ LLM å›æ‡‰
            async def mock_astream(messages):
                chunks = ["æ©Ÿå™¨", "å­¸ç¿’", "æ˜¯", "ä¸€ç¨®", "è®“", "é›»è…¦", "å­¸ç¿’", "çš„", "æŠ€è¡“"]
                for chunk in chunks:
                    yield Mock(content=chunk)
                yield Mock(content="")  # çµæŸæ¨™è¨˜
            
            with patch.object(agent, 'final_answer_llm') as mock_llm:
                mock_llm.astream = mock_astream
                
                # æ¨¡æ“¬é€²åº¦è§€å¯Ÿè€…
                progress_observer = Mock()
                progress_observer.on_streaming_chunk = AsyncMock()
                progress_observer.on_streaming_complete = AsyncMock()
                agent.add_progress_observer(progress_observer)
                
                # åŸ·è¡Œæœ€çµ‚ç­”æ¡ˆç”Ÿæˆ
                result = await agent.finalize_answer(test_state)
                
                # é©—è­‰ä¸²æµçµæœ
                assert result["finished"] is True
                assert "æ©Ÿå™¨å­¸ç¿’æ˜¯ä¸€ç¨®è®“é›»è…¦å­¸ç¿’çš„æŠ€è¡“" in result["final_answer"]
                
                # é©—è­‰ä¸²æµå›èª¿è¢«èª¿ç”¨
                assert progress_observer.on_streaming_chunk.call_count >= 9
                progress_observer.on_streaming_complete.assert_called_once()
    
    def test_persona_integration(self):
        """æ¸¬è©¦ Persona ç³»çµ±æ•´åˆ"""
        config = get_comprehensive_test_config()
        
        with patch.dict('os.environ', {'GEMINI_API_KEY': 'test_key_12345'}):
            agent = UnifiedAgent(config)
            
            # æ¸¬è©¦ persona è¼‰å…¥
            assert agent.prompt_system is not None
            
            # æ¸¬è©¦ system prompt æ§‹å»º
            with patch.object(agent.prompt_system, 'get_system_instructions') as mock_get_system:
                mock_get_system.return_value = "ä½ æ˜¯ä¸€å€‹æœ‰ç”¨çš„åŠ©æ‰‹ï¼Œå…·æœ‰å‹å–„çš„å€‹æ€§ã€‚"
                
                messages = [MsgNode(role="user", content="ä½ å¥½")]
                system_prompt = agent._build_final_system_prompt("", "")
                
                # é©—è­‰ system prompt åŒ…å« persona è³‡è¨Š
                mock_get_system.assert_called_once()
                assert isinstance(system_prompt, str)
                assert len(system_prompt) > 0
    
    def test_cli_interface(self):
        """æ¸¬è©¦ CLI ä»‹é¢é…ç½®è™•ç†"""
        # ç°¡åŒ–çš„ CLI æ¸¬è©¦ï¼Œåªæ¸¬è©¦é…ç½®è™•ç†
        test_config = get_comprehensive_test_config()
        test_config.agent.behavior.max_tool_rounds = 0  # ç¦ç”¨å·¥å…·
        
        # é©—è­‰é…ç½®æ­£ç¢ºè¨­ç½®
        assert test_config.agent.behavior.max_tool_rounds == 0
        assert isinstance(test_config, AppConfig)
    
    def test_configuration_system(self):
        """æ¸¬è©¦é…ç½®ç³»çµ±"""
        # æ¸¬è©¦å‹åˆ¥å®‰å…¨é…ç½®è¼‰å…¥
        config = get_comprehensive_test_config()
        
        # é©—è­‰é…ç½®çµæ§‹
        assert isinstance(config.agent, AgentConfig)
        assert isinstance(config.discord, DiscordConfig)
        assert isinstance(config.llm, LLMConfig)
        assert isinstance(config.streaming, StreamingConfig)
        
        # æ¸¬è©¦é…ç½®é©—è­‰
        assert config.agent.behavior.max_tool_rounds == 2
        assert config.streaming.enabled is True
        assert config.discord.enable_conversation_history is True
        
        # æ¸¬è©¦å·¥å…·é…ç½®
        assert "google_search" in config.agent.tools
        assert config.agent.tools["google_search"].enabled is True
        
        # æ¸¬è©¦é è¨­å€¼å›é€€
        assert config.streaming.min_content_length == 100
    
    @pytest.mark.asyncio
    async def test_error_handling(self):
        """æ¸¬è©¦éŒ¯èª¤è™•ç†æ©Ÿåˆ¶"""
        config = get_comprehensive_test_config()
        
        with patch.dict('os.environ', {'GEMINI_API_KEY': 'test_key_12345'}):
            agent = UnifiedAgent(config)
            
            # æ¸¬è©¦ LLM èª¿ç”¨å¤±æ•—çš„éŒ¯èª¤è™•ç†
            test_state = OverallState(
                messages=[MsgNode(role="user", content="æ¸¬è©¦éŒ¯èª¤è™•ç†")],
                finished=False
            )
            
            with patch.object(agent, 'final_answer_llm') as mock_llm:
                # æ¨¡æ“¬ LLM èª¿ç”¨å¤±æ•—
                mock_llm.invoke.side_effect = Exception("LLM èª¿ç”¨å¤±æ•—")
                
                # åŸ·è¡Œæœ€çµ‚ç­”æ¡ˆç”Ÿæˆ
                result = await agent.finalize_answer(test_state)
                
                # é©—è­‰éŒ¯èª¤è™•ç†
                assert result["finished"] is True
                # åœ¨ä¸²æµæ¨¡å¼ä¸‹ï¼ŒéŒ¯èª¤å¯èƒ½å°è‡´ç©ºå­—ä¸²ï¼Œé€™ä¹Ÿæ˜¯ä¸€ç¨®éŒ¯èª¤è™•ç†æ–¹å¼
                assert isinstance(result["final_answer"], str)
    
    @pytest.mark.asyncio
    async def test_parallel_tool_execution(self):
        """æ¸¬è©¦ä¸¦è¡Œå·¥å…·åŸ·è¡Œ"""
        config = get_comprehensive_test_config()
        
        with patch.dict('os.environ', {'GEMINI_API_KEY': 'test_key_12345'}):
            agent = UnifiedAgent(config)
            
            # æº–å‚™æ¸¬è©¦ç‹€æ…‹
            initial_state = OverallState(
                messages=[MsgNode(role="user", content="æœå°‹ Python å’Œ JavaScript çš„æ¯”è¼ƒ")],
                tool_round=0,
                finished=False
            )
            
            # ç”±æ–¼ tool_analysis_llm æœªåˆå§‹åŒ–ï¼Œæœƒä½¿ç”¨å›é€€é‚è¼¯
            # åŸ·è¡Œè¨ˆåŠƒç”Ÿæˆ
            result = await agent.generate_query_or_plan(initial_state)
            
            # é©—è­‰è¨ˆåŠƒç”Ÿæˆçµæœï¼ˆä½¿ç”¨å›é€€é‚è¼¯ï¼‰
            assert "agent_plan" in result
            assert result["agent_plan"].reasoning == "LLM æœªå¯ç”¨ï¼Œä½¿ç”¨ç°¡åŒ–é‚è¼¯æ±ºç­–"
            
            # æ¸¬è©¦è·¯ç”±æ±ºç­–
            updated_state = OverallState(
                messages=initial_state.messages,
                tool_round=result["tool_round"],
                finished=initial_state.finished,
                agent_plan=result["agent_plan"]
            )
            route_result = agent.route_and_dispatch_tools(updated_state)
            
            # é©—è­‰è·¯ç”±çµæœ
            assert isinstance(route_result, str)
            assert route_result in ["execute_tools", "direct_answer"]


if __name__ == "__main__":
    pytest.main([__file__, "-v"]) 